{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267d3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84e5516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Conler\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>chest_ACC_x_mean</th>\n",
       "      <th>chest_ACC_y_mean</th>\n",
       "      <th>chest_ACC_z_mean</th>\n",
       "      <th>chest_ECG_mean</th>\n",
       "      <th>chest_Resp_mean</th>\n",
       "      <th>wrist_ACC_x_mean</th>\n",
       "      <th>wrist_ACC_y_mean</th>\n",
       "      <th>wrist_ACC_z_mean</th>\n",
       "      <th>wrist_EDA_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>wrist_TEMP_median</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>SKIN</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>Rpeaks</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.611369</td>\n",
       "      <td>0.851230</td>\n",
       "      <td>-0.066021</td>\n",
       "      <td>-0.369793</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>1.320817</td>\n",
       "      <td>-0.761230</td>\n",
       "      <td>-0.076416</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.716672</td>\n",
       "      <td>...</td>\n",
       "      <td>32.155</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.323992</td>\n",
       "      <td>0.853035</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>-0.372883</td>\n",
       "      <td>-0.037044</td>\n",
       "      <td>-1.524349</td>\n",
       "      <td>-0.766602</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>4.692810</td>\n",
       "      <td>...</td>\n",
       "      <td>32.150</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.708336</td>\n",
       "      <td>0.862127</td>\n",
       "      <td>-0.063661</td>\n",
       "      <td>-0.328341</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>-0.871338</td>\n",
       "      <td>-0.362305</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>4.709465</td>\n",
       "      <td>...</td>\n",
       "      <td>32.150</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.640794</td>\n",
       "      <td>0.884370</td>\n",
       "      <td>-0.063035</td>\n",
       "      <td>-0.265127</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.409606</td>\n",
       "      <td>-0.979004</td>\n",
       "      <td>-0.150635</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>4.748541</td>\n",
       "      <td>...</td>\n",
       "      <td>32.140</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.658406</td>\n",
       "      <td>0.889886</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>-0.247533</td>\n",
       "      <td>-0.024418</td>\n",
       "      <td>-0.779251</td>\n",
       "      <td>-1.002930</td>\n",
       "      <td>-0.099609</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>4.765036</td>\n",
       "      <td>...</td>\n",
       "      <td>32.155</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64692</th>\n",
       "      <td>75.475622</td>\n",
       "      <td>0.894839</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>-0.214601</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.712193</td>\n",
       "      <td>-0.710205</td>\n",
       "      <td>0.671631</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.956780</td>\n",
       "      <td>...</td>\n",
       "      <td>34.015</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64693</th>\n",
       "      <td>77.524511</td>\n",
       "      <td>0.895650</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>-0.217153</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.364633</td>\n",
       "      <td>-0.454102</td>\n",
       "      <td>-0.193848</td>\n",
       "      <td>0.840088</td>\n",
       "      <td>0.943969</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64694</th>\n",
       "      <td>78.714945</td>\n",
       "      <td>0.893826</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>-0.202851</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>-0.179085</td>\n",
       "      <td>-0.669678</td>\n",
       "      <td>-0.124756</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.943969</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64695</th>\n",
       "      <td>80.413954</td>\n",
       "      <td>0.896889</td>\n",
       "      <td>0.022090</td>\n",
       "      <td>-0.203860</td>\n",
       "      <td>-0.013849</td>\n",
       "      <td>0.442674</td>\n",
       "      <td>-0.351074</td>\n",
       "      <td>-0.044678</td>\n",
       "      <td>0.890381</td>\n",
       "      <td>0.937724</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64696</th>\n",
       "      <td>80.853007</td>\n",
       "      <td>0.892864</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>-0.226432</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>-0.516357</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.585449</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64697 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  chest_ACC_x_mean  chest_ACC_y_mean  chest_ACC_z_mean  \\\n",
       "0      49.611369          0.851230         -0.066021         -0.369793   \n",
       "1      50.323992          0.853035         -0.064653         -0.372883   \n",
       "2      52.708336          0.862127         -0.063661         -0.328341   \n",
       "3      55.640794          0.884370         -0.063035         -0.265127   \n",
       "4      57.658406          0.889886         -0.042930         -0.247533   \n",
       "...          ...               ...               ...               ...   \n",
       "64692  75.475622          0.894839          0.011158         -0.214601   \n",
       "64693  77.524511          0.895650          0.014221         -0.217153   \n",
       "64694  78.714945          0.893826          0.022179         -0.202851   \n",
       "64695  80.413954          0.896889          0.022090         -0.203860   \n",
       "64696  80.853007          0.892864          0.013154         -0.226432   \n",
       "\n",
       "       chest_ECG_mean  chest_Resp_mean  wrist_ACC_x_mean  wrist_ACC_y_mean  \\\n",
       "0            0.039022         1.320817         -0.761230         -0.076416   \n",
       "1           -0.037044        -1.524349         -0.766602         -0.076172   \n",
       "2            0.021329         0.497232         -0.871338         -0.362305   \n",
       "3            0.006393         0.409606         -0.979004         -0.150635   \n",
       "4           -0.024418        -0.779251         -1.002930         -0.099609   \n",
       "...               ...              ...               ...               ...   \n",
       "64692       -0.008444         0.712193         -0.710205          0.671631   \n",
       "64693        0.000331         0.364633         -0.454102         -0.193848   \n",
       "64694        0.021754        -0.179085         -0.669678         -0.124756   \n",
       "64695       -0.013849         0.442674         -0.351074         -0.044678   \n",
       "64696       -0.002727         0.611511         -0.516357          0.049561   \n",
       "\n",
       "       wrist_ACC_z_mean  wrist_EDA_mean  ...  wrist_TEMP_median  WEIGHT  \\\n",
       "0              0.671875        4.716672  ...             32.155    78.0   \n",
       "1              0.680420        4.692810  ...             32.150    78.0   \n",
       "2              0.287842        4.709465  ...             32.150    78.0   \n",
       "3              0.195068        4.748541  ...             32.140    78.0   \n",
       "4              0.148926        4.765036  ...             32.155    78.0   \n",
       "...                 ...             ...  ...                ...     ...   \n",
       "64692          0.156250        0.956780  ...             34.015    79.0   \n",
       "64693          0.840088        0.943969  ...             34.000    79.0   \n",
       "64694          0.505371        0.943969  ...             34.000    79.0   \n",
       "64695          0.890381        0.937724  ...             34.000    79.0   \n",
       "64696          0.585449        0.930038  ...             34.000    79.0   \n",
       "\n",
       "       Gender  AGE  HEIGHT  SKIN  SPORT  Rpeaks  Activity  Subject  \n",
       "0           1   34   182.0     3      6       0         0       S1  \n",
       "1           1   34   182.0     3      6       1         0       S1  \n",
       "2           1   34   182.0     3      6       0         0       S1  \n",
       "3           1   34   182.0     3      6       0         0       S1  \n",
       "4           1   34   182.0     3      6       0         0       S1  \n",
       "...       ...  ...     ...   ...    ...     ...       ...      ...  \n",
       "64692       1   28   183.0     2      5       1         2      S15  \n",
       "64693       1   28   183.0     2      5       0         2      S15  \n",
       "64694       1   28   183.0     2      5       1         2      S15  \n",
       "64695       1   28   183.0     2      5       0         2      S15  \n",
       "64696       1   28   183.0     2      5       1         2      S15  \n",
       "\n",
       "[64697 rows x 43 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/dataset_cal.csv')\n",
    "\n",
    "S1 = data.loc[data['Subject'] == 'S1']\n",
    "S1['Gender'].replace(' f', 0, inplace=True)\n",
    "S1['Gender'].replace(' m', 1, inplace=True)\n",
    "\n",
    "remove = [\"Subject\", \"Activity\"]\n",
    "features = [column for column in list(data.columns) if column not in remove]\n",
    "data['Gender'].replace(' f', 0, inplace=True)\n",
    "data['Gender'].replace(' m', 1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c1effd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Conler\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns = ['WEIGHT','Gender', 'AGE', 'HEIGHT', 'SKIN', 'SPORT', 'Activity','Subject' ], inplace = True)\n",
    "S1.drop(columns = ['WEIGHT','Gender', 'AGE', 'HEIGHT', 'SKIN', 'SPORT', 'Activity','Subject' ], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aa2f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chest_ACC_x_mean</th>\n",
       "      <th>chest_ACC_y_mean</th>\n",
       "      <th>chest_ACC_z_mean</th>\n",
       "      <th>chest_ECG_mean</th>\n",
       "      <th>chest_Resp_mean</th>\n",
       "      <th>wrist_ACC_x_mean</th>\n",
       "      <th>wrist_ACC_y_mean</th>\n",
       "      <th>wrist_ACC_z_mean</th>\n",
       "      <th>wrist_EDA_mean</th>\n",
       "      <th>wrist_BVP_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>chest_ACC_z_median</th>\n",
       "      <th>chest_ECG_median</th>\n",
       "      <th>chest_Resp_median</th>\n",
       "      <th>wrist_ACC_x_median</th>\n",
       "      <th>wrist_ACC_y_median</th>\n",
       "      <th>wrist_ACC_z_median</th>\n",
       "      <th>wrist_EDA_median</th>\n",
       "      <th>wrist_BVP_median</th>\n",
       "      <th>wrist_TEMP_median</th>\n",
       "      <th>Rpeaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.851230</td>\n",
       "      <td>-0.066021</td>\n",
       "      <td>-0.369793</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>1.320817</td>\n",
       "      <td>-0.761230</td>\n",
       "      <td>-0.076416</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.716672</td>\n",
       "      <td>-7.619219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3698</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>1.320648</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.716672</td>\n",
       "      <td>-2.425</td>\n",
       "      <td>32.154999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853035</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>-0.372883</td>\n",
       "      <td>-0.037044</td>\n",
       "      <td>-1.524349</td>\n",
       "      <td>-0.766602</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>4.692810</td>\n",
       "      <td>7.464063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3742</td>\n",
       "      <td>-0.037857</td>\n",
       "      <td>-2.276611</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.693611</td>\n",
       "      <td>15.590</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862127</td>\n",
       "      <td>-0.063661</td>\n",
       "      <td>-0.328341</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>-0.871338</td>\n",
       "      <td>-0.362305</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>4.709465</td>\n",
       "      <td>-19.324688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3374</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>-0.828125</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>4.710907</td>\n",
       "      <td>-14.910</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884370</td>\n",
       "      <td>-0.063035</td>\n",
       "      <td>-0.265127</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.409606</td>\n",
       "      <td>-0.979004</td>\n",
       "      <td>-0.150635</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>4.748541</td>\n",
       "      <td>10.776719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2516</td>\n",
       "      <td>-0.044014</td>\n",
       "      <td>0.433350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>4.748061</td>\n",
       "      <td>14.345</td>\n",
       "      <td>32.139999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889886</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>-0.247533</td>\n",
       "      <td>-0.024418</td>\n",
       "      <td>-0.779251</td>\n",
       "      <td>-1.002930</td>\n",
       "      <td>-0.099609</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>4.765036</td>\n",
       "      <td>15.263047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2472</td>\n",
       "      <td>-0.037651</td>\n",
       "      <td>-0.827789</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>4.764075</td>\n",
       "      <td>38.125</td>\n",
       "      <td>32.154999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.724237</td>\n",
       "      <td>-0.072968</td>\n",
       "      <td>-0.607304</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>-1.207002</td>\n",
       "      <td>-0.529297</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.864258</td>\n",
       "      <td>2.676020</td>\n",
       "      <td>1.094062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6082</td>\n",
       "      <td>-0.073929</td>\n",
       "      <td>-2.778625</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.676661</td>\n",
       "      <td>16.865</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.807758</td>\n",
       "      <td>-0.066048</td>\n",
       "      <td>-0.446783</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>5.118846</td>\n",
       "      <td>-0.721924</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.665771</td>\n",
       "      <td>2.688992</td>\n",
       "      <td>37.669220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4227</td>\n",
       "      <td>-0.062050</td>\n",
       "      <td>6.322479</td>\n",
       "      <td>-0.671875</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2.688191</td>\n",
       "      <td>50.770</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.901212</td>\n",
       "      <td>-0.016409</td>\n",
       "      <td>-0.078395</td>\n",
       "      <td>-0.032977</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>-0.387207</td>\n",
       "      <td>0.879395</td>\n",
       "      <td>0.297852</td>\n",
       "      <td>2.761859</td>\n",
       "      <td>-41.876953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1264</td>\n",
       "      <td>-0.105606</td>\n",
       "      <td>-1.041412</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>2.740079</td>\n",
       "      <td>-25.340</td>\n",
       "      <td>34.380001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>0.896119</td>\n",
       "      <td>-0.086879</td>\n",
       "      <td>-0.203028</td>\n",
       "      <td>0.007409</td>\n",
       "      <td>-2.420330</td>\n",
       "      <td>-0.422607</td>\n",
       "      <td>0.950195</td>\n",
       "      <td>0.303955</td>\n",
       "      <td>3.156301</td>\n",
       "      <td>5.619297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2116</td>\n",
       "      <td>-0.056259</td>\n",
       "      <td>-2.278137</td>\n",
       "      <td>-0.429688</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>3.198100</td>\n",
       "      <td>-4.935</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>0.872379</td>\n",
       "      <td>-0.102528</td>\n",
       "      <td>-0.144576</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>-2.969160</td>\n",
       "      <td>-0.195801</td>\n",
       "      <td>0.925781</td>\n",
       "      <td>0.223145</td>\n",
       "      <td>3.277212</td>\n",
       "      <td>-1.244375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2132</td>\n",
       "      <td>-0.052277</td>\n",
       "      <td>-2.315521</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.195312</td>\n",
       "      <td>3.275610</td>\n",
       "      <td>6.955</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4603 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chest_ACC_x_mean  chest_ACC_y_mean  chest_ACC_z_mean  chest_ECG_mean  \\\n",
       "0             0.851230         -0.066021         -0.369793        0.039022   \n",
       "1             0.853035         -0.064653         -0.372883       -0.037044   \n",
       "2             0.862127         -0.063661         -0.328341        0.021329   \n",
       "3             0.884370         -0.063035         -0.265127        0.006393   \n",
       "4             0.889886         -0.042930         -0.247533       -0.024418   \n",
       "...                ...               ...               ...             ...   \n",
       "4598          0.724237         -0.072968         -0.607304        0.015020   \n",
       "4599          0.807758         -0.066048         -0.446783        0.004991   \n",
       "4600          0.901212         -0.016409         -0.078395       -0.032977   \n",
       "4601          0.896119         -0.086879         -0.203028        0.007409   \n",
       "4602          0.872379         -0.102528         -0.144576        0.028282   \n",
       "\n",
       "      chest_Resp_mean  wrist_ACC_x_mean  wrist_ACC_y_mean  wrist_ACC_z_mean  \\\n",
       "0            1.320817         -0.761230         -0.076416          0.671875   \n",
       "1           -1.524349         -0.766602         -0.076172          0.680420   \n",
       "2            0.497232         -0.871338         -0.362305          0.287842   \n",
       "3            0.409606         -0.979004         -0.150635          0.195068   \n",
       "4           -0.779251         -1.002930         -0.099609          0.148926   \n",
       "...               ...               ...               ...               ...   \n",
       "4598        -1.207002         -0.529297          0.000977          0.864258   \n",
       "4599         5.118846         -0.721924          0.005859          0.665771   \n",
       "4600         0.019999         -0.387207          0.879395          0.297852   \n",
       "4601        -2.420330         -0.422607          0.950195          0.303955   \n",
       "4602        -2.969160         -0.195801          0.925781          0.223145   \n",
       "\n",
       "      wrist_EDA_mean  wrist_BVP_mean  ...  chest_ACC_z_median  \\\n",
       "0           4.716672       -7.619219  ...             -0.3698   \n",
       "1           4.692810        7.464063  ...             -0.3742   \n",
       "2           4.709465      -19.324688  ...             -0.3374   \n",
       "3           4.748541       10.776719  ...             -0.2516   \n",
       "4           4.765036       15.263047  ...             -0.2472   \n",
       "...              ...             ...  ...                 ...   \n",
       "4598        2.676020        1.094062  ...             -0.6082   \n",
       "4599        2.688992       37.669220  ...             -0.4227   \n",
       "4600        2.761859      -41.876953  ...             -0.1264   \n",
       "4601        3.156301        5.619297  ...             -0.2116   \n",
       "4602        3.277212       -1.244375  ...             -0.2132   \n",
       "\n",
       "      chest_ECG_median  chest_Resp_median  wrist_ACC_x_median  \\\n",
       "0            -0.003960           1.320648           -0.765625   \n",
       "1            -0.037857          -2.276611           -0.765625   \n",
       "2            -0.026161           0.612640           -0.828125   \n",
       "3            -0.044014           0.433350           -1.000000   \n",
       "4            -0.037651          -0.827789           -1.000000   \n",
       "...                ...                ...                 ...   \n",
       "4598         -0.073929          -2.778625           -0.531250   \n",
       "4599         -0.062050           6.322479           -0.671875   \n",
       "4600         -0.105606          -1.041412           -0.375000   \n",
       "4601         -0.056259          -2.278137           -0.429688   \n",
       "4602         -0.052277          -2.315521           -0.171875   \n",
       "\n",
       "      wrist_ACC_y_median  wrist_ACC_z_median  wrist_EDA_median  \\\n",
       "0              -0.078125            0.671875          4.716672   \n",
       "1              -0.078125            0.671875          4.693611   \n",
       "2              -0.406250            0.296875          4.710907   \n",
       "3              -0.125000            0.156250          4.748061   \n",
       "4              -0.078125            0.140625          4.764075   \n",
       "...                  ...                 ...               ...   \n",
       "4598            0.000000            0.859375          2.676661   \n",
       "4599           -0.070312            0.718750          2.688191   \n",
       "4600            0.851562            0.312500          2.740079   \n",
       "4601            0.890625            0.328125          3.198100   \n",
       "4602            0.968750            0.195312          3.275610   \n",
       "\n",
       "      wrist_BVP_median  wrist_TEMP_median  Rpeaks  \n",
       "0               -2.425          32.154999     0.0  \n",
       "1               15.590          32.150002     1.0  \n",
       "2              -14.910          32.150002     0.0  \n",
       "3               14.345          32.139999     0.0  \n",
       "4               38.125          32.154999     0.0  \n",
       "...                ...                ...     ...  \n",
       "4598            16.865          34.389999     1.0  \n",
       "4599            50.770          34.389999     0.0  \n",
       "4600           -25.340          34.380001     1.0  \n",
       "4601            -4.935          34.369999     0.0  \n",
       "4602             6.955          34.389999     1.0  \n",
       "\n",
       "[4603 rows x 34 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['label']\n",
    "X = data.drop(columns = ['label'],inplace = False)\n",
    "S1_y = S1['label']\n",
    "S1_X = S1.drop(columns = ['label'],inplace = False)\n",
    "S1_y.astype(np.float32)\n",
    "S1_X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00da9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38818, 34) (38818,) (25879, 34) (25879,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chest_ACC_x_mean</th>\n",
       "      <th>chest_ACC_y_mean</th>\n",
       "      <th>chest_ACC_z_mean</th>\n",
       "      <th>chest_ECG_mean</th>\n",
       "      <th>chest_Resp_mean</th>\n",
       "      <th>wrist_ACC_x_mean</th>\n",
       "      <th>wrist_ACC_y_mean</th>\n",
       "      <th>wrist_ACC_z_mean</th>\n",
       "      <th>wrist_EDA_mean</th>\n",
       "      <th>wrist_BVP_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>chest_ACC_z_median</th>\n",
       "      <th>chest_ECG_median</th>\n",
       "      <th>chest_Resp_median</th>\n",
       "      <th>wrist_ACC_x_median</th>\n",
       "      <th>wrist_ACC_y_median</th>\n",
       "      <th>wrist_ACC_z_median</th>\n",
       "      <th>wrist_EDA_median</th>\n",
       "      <th>wrist_BVP_median</th>\n",
       "      <th>wrist_TEMP_median</th>\n",
       "      <th>Rpeaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.851230</td>\n",
       "      <td>-0.066021</td>\n",
       "      <td>-0.369793</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>1.320817</td>\n",
       "      <td>-0.761230</td>\n",
       "      <td>-0.076416</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.716672</td>\n",
       "      <td>-7.619219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3698</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>1.320648</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.716672</td>\n",
       "      <td>-2.425</td>\n",
       "      <td>32.154999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853035</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>-0.372883</td>\n",
       "      <td>-0.037044</td>\n",
       "      <td>-1.524349</td>\n",
       "      <td>-0.766602</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>4.692810</td>\n",
       "      <td>7.464063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3742</td>\n",
       "      <td>-0.037857</td>\n",
       "      <td>-2.276611</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>4.693611</td>\n",
       "      <td>15.590</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862127</td>\n",
       "      <td>-0.063661</td>\n",
       "      <td>-0.328341</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>-0.871338</td>\n",
       "      <td>-0.362305</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>4.709465</td>\n",
       "      <td>-19.324688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3374</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>-0.828125</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>4.710907</td>\n",
       "      <td>-14.910</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884370</td>\n",
       "      <td>-0.063035</td>\n",
       "      <td>-0.265127</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.409606</td>\n",
       "      <td>-0.979004</td>\n",
       "      <td>-0.150635</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>4.748541</td>\n",
       "      <td>10.776719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2516</td>\n",
       "      <td>-0.044014</td>\n",
       "      <td>0.433350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>4.748061</td>\n",
       "      <td>14.345</td>\n",
       "      <td>32.139999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889886</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>-0.247533</td>\n",
       "      <td>-0.024418</td>\n",
       "      <td>-0.779251</td>\n",
       "      <td>-1.002930</td>\n",
       "      <td>-0.099609</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>4.765036</td>\n",
       "      <td>15.263047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2472</td>\n",
       "      <td>-0.037651</td>\n",
       "      <td>-0.827789</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>4.764075</td>\n",
       "      <td>38.125</td>\n",
       "      <td>32.154999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64692</th>\n",
       "      <td>0.894839</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>-0.214601</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.712193</td>\n",
       "      <td>-0.710205</td>\n",
       "      <td>0.671631</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.956779</td>\n",
       "      <td>-3.816328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2202</td>\n",
       "      <td>-0.039688</td>\n",
       "      <td>0.665283</td>\n",
       "      <td>-0.640625</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.951496</td>\n",
       "      <td>-9.900</td>\n",
       "      <td>34.014999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64693</th>\n",
       "      <td>0.895650</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>-0.217153</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.364633</td>\n",
       "      <td>-0.454102</td>\n",
       "      <td>-0.193848</td>\n",
       "      <td>0.840088</td>\n",
       "      <td>0.943969</td>\n",
       "      <td>-6.773203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2168</td>\n",
       "      <td>-0.045273</td>\n",
       "      <td>-0.077820</td>\n",
       "      <td>-0.429688</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.941887</td>\n",
       "      <td>-6.995</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64694</th>\n",
       "      <td>0.893826</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>-0.202851</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>-0.179085</td>\n",
       "      <td>-0.669678</td>\n",
       "      <td>-0.124756</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.943969</td>\n",
       "      <td>8.764375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2136</td>\n",
       "      <td>-0.029800</td>\n",
       "      <td>0.343323</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.945090</td>\n",
       "      <td>10.175</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64695</th>\n",
       "      <td>0.896889</td>\n",
       "      <td>0.022090</td>\n",
       "      <td>-0.203860</td>\n",
       "      <td>-0.013849</td>\n",
       "      <td>0.442674</td>\n",
       "      <td>-0.351074</td>\n",
       "      <td>-0.044678</td>\n",
       "      <td>0.890381</td>\n",
       "      <td>0.937724</td>\n",
       "      <td>-6.218515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2038</td>\n",
       "      <td>-0.056717</td>\n",
       "      <td>0.968933</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.939965</td>\n",
       "      <td>-6.620</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64696</th>\n",
       "      <td>0.892864</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>-0.226432</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>-0.516357</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.585449</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>1.324844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2246</td>\n",
       "      <td>-0.022156</td>\n",
       "      <td>-0.563049</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.931639</td>\n",
       "      <td>4.745</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64697 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chest_ACC_x_mean  chest_ACC_y_mean  chest_ACC_z_mean  chest_ECG_mean  \\\n",
       "0              0.851230         -0.066021         -0.369793        0.039022   \n",
       "1              0.853035         -0.064653         -0.372883       -0.037044   \n",
       "2              0.862127         -0.063661         -0.328341        0.021329   \n",
       "3              0.884370         -0.063035         -0.265127        0.006393   \n",
       "4              0.889886         -0.042930         -0.247533       -0.024418   \n",
       "...                 ...               ...               ...             ...   \n",
       "64692          0.894839          0.011158         -0.214601       -0.008444   \n",
       "64693          0.895650          0.014221         -0.217153        0.000331   \n",
       "64694          0.893826          0.022179         -0.202851        0.021754   \n",
       "64695          0.896889          0.022090         -0.203860       -0.013849   \n",
       "64696          0.892864          0.013154         -0.226432       -0.002727   \n",
       "\n",
       "       chest_Resp_mean  wrist_ACC_x_mean  wrist_ACC_y_mean  wrist_ACC_z_mean  \\\n",
       "0             1.320817         -0.761230         -0.076416          0.671875   \n",
       "1            -1.524349         -0.766602         -0.076172          0.680420   \n",
       "2             0.497232         -0.871338         -0.362305          0.287842   \n",
       "3             0.409606         -0.979004         -0.150635          0.195068   \n",
       "4            -0.779251         -1.002930         -0.099609          0.148926   \n",
       "...                ...               ...               ...               ...   \n",
       "64692         0.712193         -0.710205          0.671631          0.156250   \n",
       "64693         0.364633         -0.454102         -0.193848          0.840088   \n",
       "64694        -0.179085         -0.669678         -0.124756          0.505371   \n",
       "64695         0.442674         -0.351074         -0.044678          0.890381   \n",
       "64696         0.611511         -0.516357          0.049561          0.585449   \n",
       "\n",
       "       wrist_EDA_mean  wrist_BVP_mean  ...  chest_ACC_z_median  \\\n",
       "0            4.716672       -7.619219  ...             -0.3698   \n",
       "1            4.692810        7.464063  ...             -0.3742   \n",
       "2            4.709465      -19.324688  ...             -0.3374   \n",
       "3            4.748541       10.776719  ...             -0.2516   \n",
       "4            4.765036       15.263047  ...             -0.2472   \n",
       "...               ...             ...  ...                 ...   \n",
       "64692        0.956779       -3.816328  ...             -0.2202   \n",
       "64693        0.943969       -6.773203  ...             -0.2168   \n",
       "64694        0.943969        8.764375  ...             -0.2136   \n",
       "64695        0.937724       -6.218515  ...             -0.2038   \n",
       "64696        0.930038        1.324844  ...             -0.2246   \n",
       "\n",
       "       chest_ECG_median  chest_Resp_median  wrist_ACC_x_median  \\\n",
       "0             -0.003960           1.320648           -0.765625   \n",
       "1             -0.037857          -2.276611           -0.765625   \n",
       "2             -0.026161           0.612640           -0.828125   \n",
       "3             -0.044014           0.433350           -1.000000   \n",
       "4             -0.037651          -0.827789           -1.000000   \n",
       "...                 ...                ...                 ...   \n",
       "64692         -0.039688           0.665283           -0.640625   \n",
       "64693         -0.045273          -0.077820           -0.429688   \n",
       "64694         -0.029800           0.343323           -0.390625   \n",
       "64695         -0.056717           0.968933           -0.312500   \n",
       "64696         -0.022156          -0.563049           -0.296875   \n",
       "\n",
       "       wrist_ACC_y_median  wrist_ACC_z_median  wrist_EDA_median  \\\n",
       "0               -0.078125            0.671875          4.716672   \n",
       "1               -0.078125            0.671875          4.693611   \n",
       "2               -0.406250            0.296875          4.710907   \n",
       "3               -0.125000            0.156250          4.748061   \n",
       "4               -0.078125            0.140625          4.764075   \n",
       "...                   ...                 ...               ...   \n",
       "64692            0.695312            0.117188          0.951496   \n",
       "64693           -0.187500            0.859375          0.941887   \n",
       "64694           -0.195312            0.882812          0.945090   \n",
       "64695           -0.046875            0.937500          0.939965   \n",
       "64696           -0.031250            0.937500          0.931639   \n",
       "\n",
       "       wrist_BVP_median  wrist_TEMP_median  Rpeaks  \n",
       "0                -2.425          32.154999     0.0  \n",
       "1                15.590          32.150002     1.0  \n",
       "2               -14.910          32.150002     0.0  \n",
       "3                14.345          32.139999     0.0  \n",
       "4                38.125          32.154999     0.0  \n",
       "...                 ...                ...     ...  \n",
       "64692            -9.900          34.014999     1.0  \n",
       "64693            -6.995          34.000000     0.0  \n",
       "64694            10.175          34.000000     1.0  \n",
       "64695            -6.620          34.000000     0.0  \n",
       "64696             4.745          34.000000     1.0  \n",
       "\n",
       "[64697 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train,  y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "y.astype(np.float32)\n",
    "X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9682c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_val = np.expand_dims(X_val, -1)\n",
    "S1_X = np.expand_dims(S1_X, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "729a9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Sequential() \n",
    "model.add(LSTM(64,return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[-1]))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add( LSTM(20,return_sequences=False)) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(1)) \n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61f9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 14.6267\n",
      "Epoch 2/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.6292\n",
      "Epoch 3/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.5360\n",
      "Epoch 4/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.3463\n",
      "Epoch 5/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.4632\n",
      "Epoch 6/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.3823\n",
      "Epoch 7/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.3005\n",
      "Epoch 8/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.2352\n",
      "Epoch 9/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.2201 \n",
      "Epoch 10/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.0733\n",
      "Epoch 11/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.0237\n",
      "Epoch 12/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 14.0866\n",
      "Epoch 13/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 13.9461\n",
      "Epoch 14/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 13.9607\n",
      "Epoch 15/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 13.9123\n",
      "Epoch 16/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 13.8764\n",
      "Epoch 17/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 13.8036\n",
      "Epoch 18/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.7934\n",
      "Epoch 19/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.6416\n",
      "Epoch 20/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.5932\n",
      "Epoch 21/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.5000\n",
      "Epoch 22/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.4295\n",
      "Epoch 23/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.5217\n",
      "Epoch 24/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.4005\n",
      "Epoch 25/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.3303\n",
      "Epoch 26/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.3062\n",
      "Epoch 27/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.3303\n",
      "Epoch 28/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.2179\n",
      "Epoch 29/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.2330\n",
      "Epoch 30/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.0681\n",
      "Epoch 31/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.1061\n",
      "Epoch 32/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.9986\n",
      "Epoch 33/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.9989\n",
      "Epoch 34/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 13.0057\n",
      "Epoch 35/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.9785\n",
      "Epoch 36/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.8516\n",
      "Epoch 37/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.8244\n",
      "Epoch 38/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.7033\n",
      "Epoch 39/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.7314\n",
      "Epoch 40/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.6497\n",
      "Epoch 41/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.6466\n",
      "Epoch 42/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.5680\n",
      "Epoch 43/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.5414\n",
      "Epoch 44/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.4827\n",
      "Epoch 45/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.4762\n",
      "Epoch 46/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.3619\n",
      "Epoch 47/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.2999\n",
      "Epoch 48/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.3504\n",
      "Epoch 49/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.2955\n",
      "Epoch 50/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 12.2166\n",
      "Epoch 51/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.2597\n",
      "Epoch 52/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.1728\n",
      "Epoch 53/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 12.1046\n",
      "Epoch 54/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.0171\n",
      "Epoch 55/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 12.0764\n",
      "Epoch 56/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 11.9538\n",
      "Epoch 57/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.9942\n",
      "Epoch 58/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 11.8393\n",
      "Epoch 59/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.8359\n",
      "Epoch 60/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.8238 0s\n",
      "Epoch 61/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.7607\n",
      "Epoch 62/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.7112\n",
      "Epoch 63/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.5891\n",
      "Epoch 64/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.6251\n",
      "Epoch 65/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.6125\n",
      "Epoch 66/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.4976\n",
      "Epoch 67/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.4522\n",
      "Epoch 68/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.4717\n",
      "Epoch 69/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.4807\n",
      "Epoch 70/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.3248\n",
      "Epoch 71/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.3103\n",
      "Epoch 72/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.2992\n",
      "Epoch 73/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.2488\n",
      "Epoch 74/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.1935\n",
      "Epoch 75/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.1218\n",
      "Epoch 76/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.0875\n",
      "Epoch 77/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.0033\n",
      "Epoch 78/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 11.0010\n",
      "Epoch 79/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.9446\n",
      "Epoch 80/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.9704\n",
      "Epoch 81/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.9080\n",
      "Epoch 82/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.8783\n",
      "Epoch 83/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.8974\n",
      "Epoch 84/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.7693\n",
      "Epoch 85/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.7131\n",
      "Epoch 86/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.6927\n",
      "Epoch 87/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.6630\n",
      "Epoch 88/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.6389\n",
      "Epoch 89/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.5613\n",
      "Epoch 90/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.5620\n",
      "Epoch 91/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.4657\n",
      "Epoch 92/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.4859\n",
      "Epoch 93/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.4308\n",
      "Epoch 94/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.3806\n",
      "Epoch 95/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.3892\n",
      "Epoch 96/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.3145\n",
      "Epoch 97/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.3329\n",
      "Epoch 98/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.2010\n",
      "Epoch 99/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.1990\n",
      "Epoch 100/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.2255\n",
      "Epoch 101/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.1506\n",
      "Epoch 102/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.1179\n",
      "Epoch 103/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.0281\n",
      "Epoch 104/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.9922\n",
      "Epoch 105/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.0212\n",
      "Epoch 106/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 10.0177\n",
      "Epoch 107/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.9546\n",
      "Epoch 108/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.8913\n",
      "Epoch 109/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.8526\n",
      "Epoch 110/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.7767\n",
      "Epoch 111/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.7813\n",
      "Epoch 112/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.7273\n",
      "Epoch 113/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.6806\n",
      "Epoch 114/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.6862\n",
      "Epoch 115/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.5641\n",
      "Epoch 116/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.5710\n",
      "Epoch 117/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.5449\n",
      "Epoch 118/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 9.5538\n",
      "Epoch 119/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 9.4655\n",
      "Epoch 120/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.4742\n",
      "Epoch 121/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 9.4298\n",
      "Epoch 122/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.3679\n",
      "Epoch 123/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.3580\n",
      "Epoch 124/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.3247\n",
      "Epoch 125/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.2983\n",
      "Epoch 126/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.3197\n",
      "Epoch 127/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.2525\n",
      "Epoch 128/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.1573\n",
      "Epoch 129/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.2268\n",
      "Epoch 130/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.1666\n",
      "Epoch 131/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.0650\n",
      "Epoch 132/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.0041\n",
      "Epoch 133/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.9531\n",
      "Epoch 134/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 9.0447\n",
      "Epoch 135/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.9213\n",
      "Epoch 136/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.9630\n",
      "Epoch 137/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.9025\n",
      "Epoch 138/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.8324\n",
      "Epoch 139/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.8390\n",
      "Epoch 140/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.7879\n",
      "Epoch 141/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.7687\n",
      "Epoch 142/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.7940\n",
      "Epoch 143/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.7326\n",
      "Epoch 144/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.6497\n",
      "Epoch 145/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.6441\n",
      "Epoch 146/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.6279\n",
      "Epoch 147/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.5868\n",
      "Epoch 148/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.5884\n",
      "Epoch 149/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.5317\n",
      "Epoch 150/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.4887\n",
      "Epoch 151/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.4063:\n",
      "Epoch 152/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.4213\n",
      "Epoch 153/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.4066\n",
      "Epoch 154/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.3366\n",
      "Epoch 155/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.3344\n",
      "Epoch 156/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.3667\n",
      "Epoch 157/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.3163\n",
      "Epoch 158/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.2822\n",
      "Epoch 159/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.2656\n",
      "Epoch 160/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.2814\n",
      "Epoch 161/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.1385\n",
      "Epoch 162/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.2283\n",
      "Epoch 163/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.1681\n",
      "Epoch 164/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.1395\n",
      "Epoch 165/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.1282\n",
      "Epoch 166/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.1361\n",
      "Epoch 167/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 8.0248\n",
      "Epoch 168/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9611\n",
      "Epoch 169/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9998\n",
      "Epoch 170/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9730\n",
      "Epoch 171/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9854\n",
      "Epoch 172/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9535\n",
      "Epoch 173/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.9342\n",
      "Epoch 174/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.8530\n",
      "Epoch 175/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.8837\n",
      "Epoch 176/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.8078\n",
      "Epoch 177/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.8085\n",
      "Epoch 178/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.8266\n",
      "Epoch 179/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.7631\n",
      "Epoch 180/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.7780\n",
      "Epoch 181/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.7052\n",
      "Epoch 182/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.7191\n",
      "Epoch 183/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.6587\n",
      "Epoch 184/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.6606\n",
      "Epoch 185/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.6287\n",
      "Epoch 186/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.6121\n",
      "Epoch 187/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.6119\n",
      "Epoch 188/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.5811\n",
      "Epoch 189/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.5859\n",
      "Epoch 190/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.5356\n",
      "Epoch 191/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.5488\n",
      "Epoch 192/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.4772\n",
      "Epoch 193/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.4681\n",
      "Epoch 194/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.5169\n",
      "Epoch 195/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.4964\n",
      "Epoch 196/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.4440\n",
      "Epoch 197/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.4073\n",
      "Epoch 198/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.3740\n",
      "Epoch 199/300\n",
      "304/304 [==============================] - 7s 24ms/step - loss: 7.3475\n",
      "Epoch 200/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.3857\n",
      "Epoch 201/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.3858\n",
      "Epoch 202/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.2987\n",
      "Epoch 203/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.2832\n",
      "Epoch 204/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.3376\n",
      "Epoch 205/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 7.2301\n",
      "Epoch 206/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.3029\n",
      "Epoch 207/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.2320\n",
      "Epoch 208/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1870\n",
      "Epoch 209/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1856\n",
      "Epoch 210/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.2126\n",
      "Epoch 211/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1577\n",
      "Epoch 212/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1709\n",
      "Epoch 213/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1622\n",
      "Epoch 214/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1199\n",
      "Epoch 215/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1149\n",
      "Epoch 216/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1170\n",
      "Epoch 217/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.0342\n",
      "Epoch 218/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.0427\n",
      "Epoch 219/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.1035\n",
      "Epoch 220/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.0098\n",
      "Epoch 221/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9767\n",
      "Epoch 222/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 7.0170\n",
      "Epoch 223/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9935\n",
      "Epoch 224/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9703\n",
      "Epoch 225/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9246\n",
      "Epoch 226/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9162\n",
      "Epoch 227/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9629\n",
      "Epoch 228/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8744\n",
      "Epoch 229/300\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 6.8895\n",
      "Epoch 230/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.9225\n",
      "Epoch 231/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8691\n",
      "Epoch 232/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8288\n",
      "Epoch 233/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8718\n",
      "Epoch 234/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8227\n",
      "Epoch 235/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7859\n",
      "Epoch 236/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7814\n",
      "Epoch 237/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8297\n",
      "Epoch 238/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7934\n",
      "Epoch 239/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.8180\n",
      "Epoch 240/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7869\n",
      "Epoch 241/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7433\n",
      "Epoch 242/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7630\n",
      "Epoch 243/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7051\n",
      "Epoch 244/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6944\n",
      "Epoch 245/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7534\n",
      "Epoch 246/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6937\n",
      "Epoch 247/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7013\n",
      "Epoch 248/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7272\n",
      "Epoch 249/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6771\n",
      "Epoch 250/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.7300\n",
      "Epoch 251/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6558\n",
      "Epoch 252/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6450\n",
      "Epoch 253/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6706\n",
      "Epoch 254/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6329\n",
      "Epoch 255/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6045\n",
      "Epoch 256/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5951\n",
      "Epoch 257/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.6363\n",
      "Epoch 258/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5561\n",
      "Epoch 259/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5699\n",
      "Epoch 260/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5592\n",
      "Epoch 261/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5790\n",
      "Epoch 262/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5522\n",
      "Epoch 263/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5686\n",
      "Epoch 264/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5814\n",
      "Epoch 265/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5986\n",
      "Epoch 266/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5187\n",
      "Epoch 267/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5351\n",
      "Epoch 268/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5194\n",
      "Epoch 269/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5547\n",
      "Epoch 270/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5044\n",
      "Epoch 271/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4688\n",
      "Epoch 272/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4552\n",
      "Epoch 273/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5394\n",
      "Epoch 274/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4686\n",
      "Epoch 275/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4852\n",
      "Epoch 276/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4220\n",
      "Epoch 277/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4360\n",
      "Epoch 278/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4436\n",
      "Epoch 279/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4547\n",
      "Epoch 280/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4300\n",
      "Epoch 281/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4045\n",
      "Epoch 282/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4123\n",
      "Epoch 283/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4421\n",
      "Epoch 284/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4005\n",
      "Epoch 285/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3903\n",
      "Epoch 286/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4073\n",
      "Epoch 287/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3832\n",
      "Epoch 288/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3510\n",
      "Epoch 289/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3726\n",
      "Epoch 290/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3754\n",
      "Epoch 291/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3822\n",
      "Epoch 292/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.4014\n",
      "Epoch 293/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3494\n",
      "Epoch 294/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.5095\n",
      "Epoch 295/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3470\n",
      "Epoch 296/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3142\n",
      "Epoch 297/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3445\n",
      "Epoch 298/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3359\n",
      "Epoch 299/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3274\n",
      "Epoch 300/300\n",
      "304/304 [==============================] - 7s 23ms/step - loss: 6.3478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a3468c4f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44393853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8.51229572e-01],\n",
       "        [-6.60207137e-02],\n",
       "        [-3.69793142e-01],\n",
       "        ...,\n",
       "        [-2.42500000e+00],\n",
       "        [ 3.21550000e+01],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 8.53035000e-01],\n",
       "        [-6.46534281e-02],\n",
       "        [-3.72883428e-01],\n",
       "        ...,\n",
       "        [ 1.55900000e+01],\n",
       "        [ 3.21500000e+01],\n",
       "        [ 1.00000000e+00]],\n",
       "\n",
       "       [[ 8.62127001e-01],\n",
       "        [-6.36612861e-02],\n",
       "        [-3.28340857e-01],\n",
       "        ...,\n",
       "        [-1.49100000e+01],\n",
       "        [ 3.21500000e+01],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 9.01211573e-01],\n",
       "        [-1.64092856e-02],\n",
       "        [-7.83952866e-02],\n",
       "        ...,\n",
       "        [-2.53400000e+01],\n",
       "        [ 3.43800000e+01],\n",
       "        [ 1.00000000e+00]],\n",
       "\n",
       "       [[ 8.96119431e-01],\n",
       "        [-8.68789999e-02],\n",
       "        [-2.03028285e-01],\n",
       "        ...,\n",
       "        [-4.93500000e+00],\n",
       "        [ 3.43700000e+01],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 8.72379142e-01],\n",
       "        [-1.02528142e-01],\n",
       "        [-1.44576143e-01],\n",
       "        ...,\n",
       "        [ 6.95500000e+00],\n",
       "        [ 3.43900000e+01],\n",
       "        [ 1.00000000e+00]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bca85e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/4291240330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mS1_pred_LR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS1_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS1_pred_LR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS1_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "S1_pred_LR = model.predict(S1_X)\n",
    "mean_absolute_error(S1_pred_LR, S1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5689c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S1_pred_LR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/619815062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mS1_pred_LR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediected forest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mS1_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Ground truth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'S1_pred_LR' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.grid(True)\n",
    "plt.plot( S1_pred_LR, label = 'prediected forest')\n",
    "plt.plot( S1_y, label = 'Ground truth')\n",
    "plt.legend()\n",
    "plt.ylabel('Heart rate - bpm', fontsize=12)\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a37da4549c61ce7b4c8b152cc7d668818c85e3625463a02de5aa58bec05eb4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
